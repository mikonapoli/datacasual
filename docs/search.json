[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi there, I am Miko.\nI am European, originally from Italy, currently residing in the UK after a decade or so of roaming around the continent.\nI am a mathematician, turned to the dark side of of the “real world” with a few fruitless postdocs under my belt.\nAfter a winding path that saw me being an intern, a knowledge/sales engineer, a product manager, I ended up in data science, learning a thing or two in the process.\nHi there, I am Miko, I’m an accidental data scientist and I learn things, because I like it and because I must.\nWelcome to my site."
  },
  {
    "objectID": "posts/2020-05-07-masked-analyst.html",
    "href": "posts/2020-05-07-masked-analyst.html",
    "title": "The masked analyst",
    "section": "",
    "text": "We are going to review the paper Effectiveness of Surgical and Cotton Masks in Blocking SARS–CoV-2: A Controlled Comparison in 4 Patients with a focus on the interpretation of the data.\n\n\n\n\n\n\nWarning\n\n\n\nalthough we are going to nitpick the small report quite a lot, this is in no way an attack on the authors or their work. In fact I consider even this minute studies quite important given the current pandemic. Furthermore: there have been comments by several people about methodological mistakes in the study. I am in no position to comment on those. In fact I want to stress out that I am in no position of advising anybody on such a delicate topic except, maybe on how to avoid some common mistakes\n\n\nApart for a personal interest in the topic of masks for source control of the COVID-19 pandemic, the two main reasons that make this paper a good subject of examination are that 1. the study is so small that we can easily rewrite the whole dataset and tear it apart at our convenience 2. it highlights a number of common pitfalls when interpreting/analysing data that any person working with data should be aware of\nThe goal of the paper, as stated by the authors themselves is\n\nTo evaluate the effectiveness of surgical and cotton masks in filtering SARS–CoV-2.\n\nIn order to do that, they selected 4 patients with COVID-19 and had them cough on a petri dish kept 20 cm away, first without a mask, then with a surgical mask, then with a cotton mask, and finally a second time without a mask. After that, both the petri dishes and the masks were examined to measure the concentration of virus particles.\nThe data gathered is all contained in this small table"
  },
  {
    "objectID": "posts/2020-05-07-masked-analyst.html#background",
    "href": "posts/2020-05-07-masked-analyst.html#background",
    "title": "The masked analyst",
    "section": "",
    "text": "We are going to review the paper Effectiveness of Surgical and Cotton Masks in Blocking SARS–CoV-2: A Controlled Comparison in 4 Patients with a focus on the interpretation of the data.\n\n\n\n\n\n\nWarning\n\n\n\nalthough we are going to nitpick the small report quite a lot, this is in no way an attack on the authors or their work. In fact I consider even this minute studies quite important given the current pandemic. Furthermore: there have been comments by several people about methodological mistakes in the study. I am in no position to comment on those. In fact I want to stress out that I am in no position of advising anybody on such a delicate topic except, maybe on how to avoid some common mistakes\n\n\nApart for a personal interest in the topic of masks for source control of the COVID-19 pandemic, the two main reasons that make this paper a good subject of examination are that 1. the study is so small that we can easily rewrite the whole dataset and tear it apart at our convenience 2. it highlights a number of common pitfalls when interpreting/analysing data that any person working with data should be aware of\nThe goal of the paper, as stated by the authors themselves is\n\nTo evaluate the effectiveness of surgical and cotton masks in filtering SARS–CoV-2.\n\nIn order to do that, they selected 4 patients with COVID-19 and had them cough on a petri dish kept 20 cm away, first without a mask, then with a surgical mask, then with a cotton mask, and finally a second time without a mask. After that, both the petri dishes and the masks were examined to measure the concentration of virus particles.\nThe data gathered is all contained in this small table"
  },
  {
    "objectID": "posts/2020-05-07-masked-analyst.html#reproducing-the-analysis",
    "href": "posts/2020-05-07-masked-analyst.html#reproducing-the-analysis",
    "title": "The masked analyst",
    "section": "Reproducing the analysis",
    "text": "Reproducing the analysis\nAs I said, the amount of data gathered is so small that we can easily rewrite it by hand and peruse it. Since I am less interested in the mask surfaces measurements, I will leave those numbers out, especially considering that they look quite bizarre (there are a number of possible explanations for the inner side of the masks having way lower concentrations of virus particles than the outer side, but they are way beyond my understanding and scope for this post).\n\n\nCode\nnaso_pha_swab = [7.68, 5.42, 5.98, 3.57]\nsaliva_swab = [4.29, 2.59, 5.91, 3.51]\ncontrol1 = [3.53, 2.14, 2.52, np.nan]\nsurgical_mask = [3.26, 1.8, 2.21, np.nan]\ncotton_mask = [2.27, np.nan, 1.42, np.nan]\ncontrol2 = [3.23, 2.06, 2.64, 2.44]\n\ndata_df = pd.DataFrame(data=[naso_pha_swab, saliva_swab, control1, control2, surgical_mask, cotton_mask], \n             columns=['patient1', 'patient2', 'patient3', 'patient4'],\n             index=['np_swab', 'saliva_swab', 'control_before', 'control_after', 'surgical_mask', 'cotton_mask']).T\n\ndata_df\n\n\n\n\n\n\n\n\n\nnp_swab\nsaliva_swab\ncontrol_before\ncontrol_after\nsurgical_mask\ncotton_mask\n\n\n\n\npatient1\n7.68\n4.29\n3.53\n3.23\n3.26\n2.27\n\n\npatient2\n5.42\n2.59\n2.14\n2.06\n1.80\nNaN\n\n\npatient3\n5.98\n5.91\n2.52\n2.64\n2.21\n1.42\n\n\npatient4\n3.57\n3.51\nNaN\n2.44\nNaN\nNaN\n\n\n\n\n\n\n\n\nProblem 1: Basic sanity check\nThere is very little in terms of description of how the data analysis has been performed. This is what I can find in the paper.\n\nThe median viral loads of nasopharyngeal and saliva samples from the 4 participants were 5.66 log copies/mL and 4.00 log copies/mL, respectively. The median viral loads after coughs without a mask, with a surgical mask, and with a cotton mask were 2.56 log copies/mL, 2.42 log copies/mL, and 1.85 log copies/mL, respectively.\n\nUnfortunately, if we try and reproduce those numbers we get something very different\n\ndata_df.median().round(2)\n\nnp_swab           5.70\nsaliva_swab       3.90\ncontrol_before    2.52\ncontrol_after     2.54\nsurgical_mask     2.21\ncotton_mask       1.84\ndtype: float64\n\n\nSolution: read the comments section\nReading the comments section of the paper, we discover that not only the authors meant mean, rather than median, but there is also a typo in the average control viral load. This is what they state the paragraph above should read:\n\nThe mean viral loads of nasopharyngeal and saliva samples from 4 participants were 5.66 log copies/mL and 4.00 log copies/mL, respectively, when we did calculate not detectable values. The mean viral loads after coughs without a mask, with a surgical mask, and with a cotton mask were 2.65 log copies/mL, 2.42 log copies/mL, and 1.85 log copies/ml, respectively, when we did not calculate not detectable values\n\nIf we check the mean rather than median, we get way closer numbers. I am still a bit uncertain about the saliva swabs mean viral load, but the other differences can definitely be attributed to rounding problems\n\ndata_df.mean().round(2)\n\nnp_swab           5.66\nsaliva_swab       4.07\ncontrol_before    2.73\ncontrol_after     2.59\nsurgical_mask     2.42\ncotton_mask       1.84\ndtype: float64\n\n\nTaking the average of the two control means, we also get a number which is quite close to the stated control viral load.\n\ndef get_control(df): return( df['control_before'] + df['control_after']) / 2\nget_control(data_df.mean().round(2)).mean()\n\n2.66\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAlways double check your numbers and do frequent sanity checks\n\n\n\n\nAside: Median or Mean?\nAlthough after the authors’ corrections the topic is not strictly relevant to our analysis, how can we decide whether to pick the median or the mean as a centrality measure?\nThe quick answer is that it is almost always a good idea to use the median rather than the mean, as it is way more robust to outliers (for a more detailed explanation you can check, for example, this post). The reason why we tend to use the mean is that it is mathematically well behaved and efficient to compute, but nowadays we can get around that with brute computational power and get something which is more robust.\nThe main exception to this rule is when you have very small samples, especially if you are measuring integers. The reason being that in this situation the median can jump around quite a bit. Let’s run a small experiment. Here is a population of 20,000 integeres normally distributed (with standard deviation 20) around a mean of 100.\n\n\nCode\npopulation = np.random.normal(100, 20, 20000).round().astype(int)\nplt.subplots(figsize=(10, 4))\nplt.hist(population, bins=50)[-1]\nplt.axvline(population.mean(), color='k', linestyle = '--');\n\n\n\n\n\n\n\n\n\nIf we draw 1000 random samples of size 4 from the population, we can see that the medians of the samples are a bit more spread out than the means (and have a higher standard deviation). This means that picking the median we are more likely to make of being further away from the true population statistics.\n\n\nCode\nsamples = [np.random.choice(population, replace=False, size=4) for _ in range(1000)]\nmedians = [np.median(x) for x in samples]\nmeans =  [np.mean(x) for x in samples]\n\nplt.hist(means, bins=100,  density=True, alpha=.7, label=f'means std: {round(np.std(means), 3)}')[-1]\nplt.hist(medians, bins=100, density=True, alpha=.7, label=f'medians std: {round(np.std(medians), 3)}')[-1]\nplt.legend();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nprefer the median over the mean, except when dealing with very small samples of integers.\n\n\nIn fact, this is exactly the situation of the paper we are looking at (the reason will be probably clearer when we get to the discussion on the units of viral loads).\n\n\nConclusions (of the paper)\nWith those numbers we have seen above in mind, the authors reach the conclusion that surgical and cotton masks are not effective at controlling the spread of COVID-19:\n\nNeither surgical nor cotton masks effectively filtered SARS–CoV-2 during coughs by infected patients […] In conclusion, both surgical and cotton masks seem to be ineffective in preventing the dissemination of SARS–CoV-2 from the coughs of patients with COVID-19 to the environment and external mask surface.\n\nAlthough they do not specify any detail, we can see that the difference in percentage of the viral load with and without a mask is roughly 9% and 30% for surgical and cotton masks respectively, which seem to support that the conclusion that these kind of masks are barely useful.\n\ndef get_test(df): return(df[['surgical_mask', 'cotton_mask']])\ndef get_difference(df, pct=True): \n    return (get_control(df) - get_test(df).T) / get_control(df) if pct else (get_control(df) - get_test(df).T)\n\nget_difference(data_df.mean().round(2))\n\nsurgical_mask    0.090226\ncotton_mask      0.308271\ndtype: float64\n\n\nEnd of the story then?\nNot exactly.\n\n\nProblem n.2: ND != NA\nAs I am sure everybody who has dabbed a bit with data science knows, one of the common themes when doing exploratory data analysis and preparing your dataset is dealing (and inputing) missing values. There are different ways of dealing with them, but the most common ones are:\n\ninput some centrality measure to fill the missing values (normally you want to use the median for continuous variable and the mode for categorical values)\nbuild a predictive model to fill the gaps and use the predictions insted\nthrow away the missing values altogether\n\nThe last one is usually the safest option, and it is what we have done so far (when we computed the mean the default behaviour is simply ignore missing values), and I assume this is what the authors mean by\n\nwhen we did not calculate not detectable values\n\nIf you check the table at the beginning of the post, though, you will see that ND stands, in fact, for “not detected”.\nThe problem here is that “not detected” does not mean that the value is missing: it means that it is too low for us to measure it. This means, in principle, that, depending on how sensitive the measure is, it could be anywhere between 0 and 1.42 (which is the smallest value measured in the table).\nLet’s see what happens if we consider 1.41, which is the most conservative value for the detectability threshold.\n\ndata_df.fillna(1.41).mean().round(2) \n\nnp_swab           5.66\nsaliva_swab       4.07\ncontrol_before    2.40\ncontrol_after     2.59\nsurgical_mask     2.17\ncotton_mask       1.63\ndtype: float64\n\n\n\nget_control(data_df.fillna(1.41).mean().round(2))\n\n2.495\n\n\n\nget_difference(data_df.fillna(1.41).mean().round(2))\n\nsurgical_mask    0.130261\ncotton_mask      0.346693\ndtype: float64\n\n\nAs we can see, even if the end result still seems to indicate that cotton and surgical masks are not particularly effective at source control, the numbers (especially for surgical masks) have changed quite a bit.\n\n\n\n\n\n\nImportant\n\n\n\npay particular attention at the semantics of unusual values. This includes missing values and outliers (for example, it is not uncommon to use “magic” dates or numbers to indicate a missing value or something specific about a piece of data). If you do not, it might completely throw off your analysis\n\n\n\n\nProblem n.3: wrong test\nAnother problem of the approach we have used so far is that the authors are (presumably) comparing the average viral loads of the same group with and without the masks. This (i.e. evaluating the differences of the averages) is the same as considering the test and control groups as independent, which is certainly not the case here as it’s the same patients being used as test and control groups. A more appropriate idea is to instead consider the differences with and without the masks for each patient independently and then averaging those differences. In other words, it is better to compute the mean of the differences rather than the difference of the mean. This is particularly important when there is a lot of variance in your test population. It is hard to tell in this case, but looking at the characteristic of the patients, they are far from a homogeneous group. Furthermore, there is really no reason not to use the appropriate test, so let’s see what happens.\n\nget_difference(data_df.fillna(1.41)).T\n\n\n\n\n\n\n\n\nsurgical_mask\ncotton_mask\n\n\n\n\npatient1\n0.035503\n0.328402\n\n\npatient2\n0.142857\n0.328571\n\n\npatient3\n0.143411\n0.449612\n\n\npatient4\n0.267532\n0.267532\n\n\n\n\n\n\n\n\nget_difference(data_df.fillna(1.41)).T.mean()\n\nsurgical_mask    0.147326\ncotton_mask      0.343530\ndtype: float64\n\n\nIn this case not much has changed (except that surgical masks look slightly better than before).\n\n\n\n\n\n\nImportant\n\n\n\ncheck your assumptions of indpendence betweeen the test and control groups (you have a test and control group, right?)\n\n\n\n\nHuge Problem n.4: watch your logs!\nIf we look carefully at the data table from the paper, we notice that there is no unit to tell us what are the numbers we are measuring. This can be found in the text though (and it is probably obvious to anyone who is used to deal with viral loads):\n\nThe median viral loads of nasopharyngeal and saliva samples from the 4 participants were 5.66 log copies/mL and 4.00 log copies/mL, respectively.\n\nHere we notice a red flag: log copies/mL seems to indicate that we are dealing with a logarithmic scale. A quick googling can confirm that: those numbers are the base 10 logarithm of the number of viral copies per milliliter. This is quite common when you are dealing with concentrations (the same thing happens, for example with pH, which is a measure of concentration of ions) as the numbers tend to be quite large and we are more interested in the order of magnitude rather than the magnitude (i.e. the actual numbers) itself.\nThis causes a massive problem, though: when we take the mean of two logarithms, we are actually taking the geometric mean of the underlying quantities, and if we consider the difference of two logarithms, we are actually looking at the ratio of the quantities.\nJust in case you need a reminder for the properties of logarithms, what we are saying is that:\n\\[ (\\log x + \\log y) / 2 = \\log { \\sqrt {xy} } \\]\nHow big of a problem this is?\nConsider this: a difference between two viral loads of 1 log copies/mL means that the larger load contains 10 times more viral particles than the smaller ones. If the two viral loads were 3 and 4 log copies/mL we would be treating a 90% difference as if it were a 25% difference. And if the two viral loads are 9 and 10 log copies/mL, we would be treating a 90% difference as if it were a 10% difference!\nAs a mathematician, my instinct would be to rewrite the formulas using the properties of the logarithms (which can be a pain or not necessarily possible), but in fact, especially when the range of values is relatively small, the easiest way to proceed is to “unroll” the logarithms and redo our computations with the actual quantities:\n\nget_difference((10 ** data_df.fillna(1.41)), pct=False).T\n\n\n\n\n\n\n\n\nsurgical_mask\ncotton_mask\n\n\n\n\npatient1\n723.641748\n2357.133893\n\n\npatient2\n63.331160\n100.722936\n\n\npatient3\n221.642467\n357.520797\n\n\npatient4\n124.859456\n124.859456\n\n\n\n\n\n\n\n\nget_difference((10 ** data_df.fillna(1.41)), pct=False).T.mean()\n\nsurgical_mask    283.368708\ncotton_mask      735.059271\ndtype: float64\n\n\nThese are the average number of viral particles filtered. How does this compare with the numbers computed before we unrolled the logarithms? It’s roughly 100 times larger.\n\n10 ** get_difference(data_df.fillna(1.41), pct=False).T.mean()\n\nsurgical_mask    2.119581\ncotton_mask      7.391796\ndtype: float64\n\n\nSo, all in al,l once we have fixed all the problems these are the filtering powers of surgical and cotton masks under our (conservative) look like this:\n\nget_difference((10 ** data_df.fillna(1.41)), pct=True).T.mean()\n\nsurgical_mask    0.548049\ncotton_mask      0.871057\ndtype: float64\n\n\nThis is a very different result from what we have obtained above as it seems to suggest that cotton masks are actually quite good at reducing the viral load spread (and remember that we are talking about coughing and being 20 cm apart, in reality this might have huge impact on the effectivness of social distancing).\n\n\n\n\n\n\nImportant\n\n\n\nalways check the units and be very cautious when using a logarithmic quantity. Try to “unroll” the log before doing your computations if the range is not too large.\n\n\nSo far I hope you are convinced that the conclusions reached in the paper is, at the very least, not that clear cut (and if you ask me in fact it’s the exact opposite of what the data is actually saying).\nBut let’s address a further criticism that is very often used to dismiss small studies.\n\n\nStatistical significance\n“Surely an experiment with N = 4 is not statistically significant” or something along those lines is a sentence that I hear far too often when evaluating the effort needed to measure an imporant quantity. Well, it turns out that until you start designing experiments and actually look at the numbers, we don’t really have an intuitive feel for sample sizes.\nLet’s see what we can do here. The first and most important problem we have is that the objective of the study is actually not well defined.\n\nTo evaluate the effectiveness of surgical and cotton masks in filtering SARS–CoV-2.\n\nAs data people we should always make sure that the question we are trying to answer is well defined from a quantitative point of view, and this particular one is not (what does “effective” means in this context)? Furhtermore, the experiment is, not designed to test how effective masks are, for example, at filtering the virus in case of people, talking, or sneezing, or even just breathing, which would be interesting for advising policies in this case.\nKeeping in mind that we are deviating from the original objective of the study, let’s see if we can formulate some question that we can try and answer with the data available.\n\n\n\n\n\n\nWarning\n\n\n\nlet me state this clearly. In general, fishing for questions after the experiment is a very bad idea and it is not how you design an experiment. This is just an exercise in measuring what can be achieved with small samples and would give us a good idea of how to design a proper study\n\n\nThese are (by patient) the reductions of viral loads in percentage between our test and control conditions:\n\neff_pcts = get_difference((10 ** data_df.fillna(1.41))).T ; eff_pcts\n\n\n\n\n\n\n\n\nsurgical_mask\ncotton_mask\n\n\n\n\npatient1\n0.284524\n0.926786\n\n\npatient2\n0.500931\n0.796689\n\n\npatient3\n0.577459\n0.931472\n\n\npatient4\n0.829282\n0.829282\n\n\n\n\n\n\n\nLet’s start with a very simple question: are masks better than nothing at reducing the viral load (under the test conditions)?\nTo appease the frequentist readers, let’s do a very basic t-test. We will do it by hand, rather than using a specific library, except for the computation of the critical thresholds.\nOur question translates into “is the filtered percentage of the viral load statistically greater than 0?” Here is is how we compute the t stats.\n\nmeans = eff_pcts.mean()\n### Notice: this is the standard error for N = 4\nstd_errors = eff_pcts.std() / 2\nt_stats = means / std_errors\n\nWe use scipy to find the critical thresholds for \\(\\alpha\\) at 0.0625, 0.05, 0.01, and 0.005. In other word we compute the value above which the t-stats need to be in order for the p-value to be below the different \\(\\alpha\\) levels and for us to reject the null hypothesis that the test condition is not better than the control condition.\nWhy and whether this is a good idea is a very long and out of scope discussion, but this is a classical and radicated method of testing hypothesis. Except for the 0.0625 one which I will explain later, the values of \\(\\alpha\\) are some of the commonly used ones in science, with 0.05 being by far the most common.\n\nfrom scipy.stats.distributions import t\nαs = [0.0625, 0.05, 0.01, 0.005]\ndf = 3\nfor α in αs: print(f'{(α) * 100}%: {t.ppf(1 - α, df)}')\n\n6.25%: 2.113086729236424\n5.0%: 2.3533634348018264\n1.0%: 4.540702858698419\n0.5%: 5.84090929975643\n\n\nSo are the t statistics higher than those values? Let’s see\n\nt_stats\n\nsurgical_mask     4.875605\ncotton_mask      25.473360\ndtype: float64\n\n\nIt turns out that both cotton and surgical masks are better than no mask in a strongly statistically significant way. Cotton masks in particular have a p-value which is way lower than the strictest normally used significance thresholds.\nIn retrospect, though, the results is not surprising: given what we know about the virus transmission it is (or should be) common sense that putting a physical barrier in front of your mount will filter at least minimally better than not putting it. And in fact I claim that this should have been our null hypothesis in the first place, but let’s not delve into that. Let’s assume that in order for masks to be effective, they need to be filtering at least 80% of the viral load. Can we say that?\n\nmeans = (eff_pcts - .8).mean()\nstd_errors = eff_pcts.std() / 2\n\n# Let's directly see the p-vaues rather than the t-stats\n(means / std_errors).apply(lambda x: 1 - t.cdf(x, df=df))\n\nsurgical_mask    0.944593\ncotton_mask      0.064624\ndtype: float64\n\n\nNot surprisingly, the answer is a resounding no for surgical masks (but at this point they were not even in the game anymore).\nWhat about cotton masks? We have a p-value of 6.5%. This is above all the thresholds so in principle we cannot reject the null hypothesis, but it would be considered “at the border of significance” if we were to submit a paper.\n\n\n\n\n\n\nImportant\n\n\n\nEven a very small sample can be statistically significant. In fact samples that are too large might have worse descriptive power, as they might amplify any sampling bias we have.\n\n\nLet’s think for a second about the values we have just seen. A p-value of 6.5% means that the average cotton mask could, in principle, not have a filtering power better than 80% as the p-value is not lower than the accepted 0.05 threshold (or any of the other thresholds we have looked at, for that matters).\nSo we should not advice wearing cotton masks, right? Well not so fast: the p-value can be thought as the fals positive rate. This means that if we see an effect (like we do in this case, as the average in our sample is over 80%) the p-value is the probability of that effect being a statistical fluke. In other words, there is a 93.5% probability that the effect we are seeing (the average filtering power is higher than 80%) is real.\nIs this enough? It depends. In particular it depends on the cost of making a mistake. In most business cases, and when the cost of getting that wrong is very low, we can accept a false positive risk way higher than the standard 5% used in science.\n\n\n\n\n\n\nImportant\n\n\n\nThere is nothing magic about the 5% statistical significance threshold. If you are doing hypothesis testing, pick a threshold that makes sense from a business perspective and consider the costs of making a mistake.\n\n\nLet’s do one last test before looking at a different trick. The question we want to answer is: are the averages filtering power of masks significantly better than the lowest values we have observed (with a weird significance threshold of 6.25%)?\n\nmeans = (eff_pcts - eff_pcts.min()).mean()\n### Notice: this is the standard error for N = 4\nstd_errors = eff_pcts.std() / 2\nt_stats = means / std_errors\ncohen_d = t_stats / 2\nt_stats.apply(lambda x: 1 - t.cdf(x, df=df))\n\nsurgical_mask    0.050409\ncotton_mask      0.058960\ndtype: float64\n\n\nUnder this conditions we can reject the null hypothesis, so we can tell that the mean filtering power higher than the smallest number observed with a probability of at least 93.75% (1 - \\(\\alpha\\)). Let’s keep this in mind and see as later we will compare it to another technique.\n\n\n\n\n\n\nWarning\n\n\n\ndoing multiple experiments with the same observations and the same \\(\\alpha\\) values is in general a very bad idea. Normally we would need to apply something like the Bonferroni correction or similar tricks. In this case, though, we are not really doing multiple experiments, but rather checking the same thing with different thresholds and probing for statistical significance, which we could have done analytically in a single go. In any case, please always be extra cautious with p-values.\n\n\n\n\nA touch of Bayes\nHypothesis testing is all fun and good, but what if we wanted to answer a question like “how much viral load on average a cotton mask filters”?\nAt this point we are out of the world of yes/no questions and we are into the world of measurement. In a certain Bayesian way of thinking, we could say that measuring something means reducing our uncertainty about the real value of that something. A good measurement consists in a range of possible values for the things we are measuring (since no measurement is without error) and a probability of the measured value to fall into that range. Essentially, the smaller the range (everything else being the same), the less our uncertainty. Measuring something, thus, means reducing the range of values we are confident enough our true value falls into.\nOne often overlooked aspect of measuring stuff (that with this very broad definition might also mean producing a report) is that each measurement has cost attached and a steeply diminishing value.\nFor example, it is extremely easy to measure my height with a .5 meters precision. Still easy with a 10 cm precision. Reasonably doable within a 1 cm. Virtually impossible and probably very expensive within a 1 \\(\\mu m\\). Not to mention completely useless.\nFor this very reason, when we have a lot of uncertainty about a certain quantity, a very small number of measurement can take us a very long way.\nIn this perspective, since a priori we know nothing about the actual value of the filtering power of cotton masks for viral loads of SARS–CoV-2, we can expect to gain a lot of insight even with the very small number of measurments we have.\nLet’s see this in practice. This is what we have measured (with the conservative assumption we are keeping about non detectable values).\n\neff_pcts = get_difference((10 ** data_df.fillna(1.41))).T.sort_values('cotton_mask')\neff_pcts.sort_values('cotton_mask').cotton_mask\n\npatient2    0.796689\npatient4    0.829282\npatient1    0.926786\npatient3    0.931472\nName: cotton_mask, dtype: float64\n\n\nOnce again, although it is not evident, “how much viral load on average a cotton mask filters” is not particularly well defined from a quantitative point of view. Let’s rephrase it as “what is the median percentage of virus load filtered by cotton masks?”.\nNow, that’s different. One of the hidden assumptions that we used during our hypotheses testing, which is almost inescapable, is that the sample we chose is not biased. In other words, we assume have selected our patients at random. This is essentially never true, and the bigger the sample, the worst the bias will be, but for the sake of argument, let’s assume that the effect of sampling bias is negligible. In this case each measurement has a 50% probability of being below the median (by definition of median itself). With a bit of combinatorics, we can compute the probability of being higher than our highest measured value, our second highest value and so on.\n\nnp.array([1/16, 4/16, 6/16, 4/16, 1/16]).cumsum()[:-1]\n\narray([0.0625, 0.3125, 0.6875, 0.9375])\n\n\nWhat we are saying is that the median filtering power of cotton masks has a 6.25% chance of being above 93%, a 31.25% of being above 92.7%, etc.\nIn other word, with only 4 values we can assert that the median is higher than the smallest measured value with 93.75% probability. And this is true no matter how the values of filtering powers are distributed.\nIf we add some very common assumptions that we have used under the hood in our t-tests (namely that the median and the mean are the same), we can say exactly the same for the mean.\nThe combinatorics behind it are beyond the scope of this post (but not complicated), but as a general rule, if we sample (measure) N values from any distribution, the probability that the median of the population (i.e. the “real” median) is higher than the smallest value we have measured is \\[ 1 - \\frac {1} {2 ^ N}\\]\nNotice that this is very close to the result we have obtained with the last t-test (so I hope now you understand the \\(\\alpha\\) value of 0.0625), but is stronger, since it is making fewer assumptions on the population and it only requires (at most) pen and paper and a quick calculation.\n\n\n\n\n\n\nImportant\n\n\n\nwhen uncertainty is large, you can get a lot of mileage from a very small sample.\n\n\n\n\nQuick power analysis\nThere is one last aspect that we have not eviscerated yet. Let’s consider once again our t-test of significance for cotton masks being more than 80% effective on average.\nWe already know that the p-value is above the \\(\\alpha\\) value of 0.05, so we cannot reject the null hypothesis. But does this mean that we have to reject the test hypotesis?\nThis is where the power come into play (or rather 1 minus the statistical power of the experiment).\nLike \\(\\alpha\\) is the acceptable risk of a false positive, there is an analogous \\(\\beta\\), which is the acceptable risk of a false negative. For some arbitrary historical reason, like we usually consider \\(\\alpha\\) to be 0.05, we consider \\(\\beta\\) to be 0.2. So the usually acceptable power of an experiment tends to be chosen as 1 - \\(\\beta\\), or 0.8. This means that in case we cannot reject the null hypothesis we want the probability of the null hypothesis being true at least 80%.\nThe statistical power is not easy to compute manually, but can it done analytically for a t-test, so we will use the statsmodels library to do so. This works allows us to fix 3 values among power, the number of observations (the parameter nobs), the chosen \\(\\alpha\\) and the effect size (long story short, in the case of the t-test is the t statistic divided by the square root of the number of observations) in order to obtain the remaining one.\nWhat’s the power of our t-test?\n\nmeans = (eff_pcts - .8).mean()\n### Notice: this is the standard error for N = 4\nstd_errors = eff_pcts.std() / 2\nt_stats = means / std_errors\ncohen_d = t_stats / 2\nt_stats.apply(lambda x: 1 - t.cdf(x, df=df))\n\n\nfrom statsmodels.stats.power import TTestPower\nTTestPower().solve_power(effect_size=cohen_d.cotton_mask, power=None, \n                             nobs=4, alpha=0.05, alternative='larger')\n\n0.48376788050332065\n\n\nA power of 48.4% (way below the acceptable 80% threshold) means that although we cannot reject the null hypothesis, there is still a 52% risk of being in presence of a false negative, which is not acceptable. So we cannot formally reject the test hypothesis either.\nWe have gained a new piece of information with our experiment, though: we are now able to guess the expected effect size if we were to repeat the experiment. And we can plug this into the power analysis to find out how many patients do we need to test in order to have an acceptable statistical power and confidence.\n\nTTestPower().solve_power(effect_size=cohen_d.cotton_mask, power=.8, \n                             nobs=None, alpha=0.05, alternative='larger')\n\n7.284382863086592\n\n\nWhat this is telling us is that the difference between what we have observed for cotton masks and a filtering power of 80% of the viral load is so strong that we only need 8 people to design a new experiment that would give us a reasonable opportunity of either rejecting the null hypothesis with 95% oconfidence or rejecting the test hypothesis with 80% confidence.\nAs menitoned above: we tend not to have a good intuition of what good sample sizes are.\n\n\n\n\n\n\nImportant\n\n\n\na very small and potentially quick study can help a lot in designing a proper statistically sound experiment. This is particularly useful for A/B testing, for example"
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html",
    "href": "posts/2020-04-19-tutti-in-maschera.html",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "",
    "text": "Tradotto dall’originale del prof. Trisha Greenhalgh OBE e di Jeremy Howard\nNon sapete cosa pensare a proposito delle mascherine? Certo, è una questione complicata, ma meno di quanto alcuni lascino intendere. Abbiamo esaminato la scienza disponibile (cfr. il nostro articolo Face Masks Against COVID-19: An Evidence Review — con non meno di 84 riferimenti bibliografici! — e Face masks for the public during the covid-19 crisis). In questo post riassiumiamo il punto di vista di diverse aree di ricerca, con la nostra interpretazione della faccenda."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#lepidemiologia-della-diffusione-della-malattia",
    "href": "posts/2020-04-19-tutti-in-maschera.html#lepidemiologia-della-diffusione-della-malattia",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "L’epidemiologia della diffusione della malattia",
    "text": "L’epidemiologia della diffusione della malattia\nSe frequentate internet anche sporadicamente, quasi sicuramente avrete visto video con trappole per topi o pezzi di domino, dove un solo evento scatena una gigantesca reazione a catena. Più vicini sono i pezzi del domino (o le trappole per topi), più la reazione è caotica. Ogni malattia infettiva ha un coefficiente di trasmissione (R0); se questo coefficiente è esattamente 1, vuol dire che ogni persona infetta, in media, contagia un’altra persona. Una malattia con R0 minore di 1 scompare nel tempo. La variante dell’influenza che ha causato la pandemia del 1918 aveva un R0 di 1,8. Per il virus che causa COVID-19 R0 è stato stimato intorno a 2,4 dai ricercatori dell’Imperial College di Londra, ma alcune ricerche suggeriscono che potrebbe addirittura arrivare a 5,7. Questo vuol dire che senza misure di contenimento, COVID-19 si diffonde moltissimo e in maniera molto rapida. Soprattutto, i pazienti con COVID-19 sono contagiosi soprattutto negli stadi iniziali della malattia (To et al. 2020; Zou et al. 2020; Bai et al. 2020; Zhang et al. 2020; Doremalen et al. 2020; Wei 2020), quando spesso presentano pochi o nessun sintomo."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#la-fisica-delle-goccioline-e-degli-aerosol",
    "href": "posts/2020-04-19-tutti-in-maschera.html#la-fisica-delle-goccioline-e-degli-aerosol",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "La fisica delle goccioline e degli aerosol",
    "text": "La fisica delle goccioline e degli aerosol\nQuando parliamo, minuscole goccioline vengono espulse dalla bocca. Nel caso in cui una persona sia infetta, queste goccioline contengono virus. Solo le goccioline più grandi durano più di un decimo di secondo prima di evaporare e trasformarsi in “nuclei”, 3-5 volte più piccoli della goccia originale, ma ancora contenenti virus (Wells 1934; Duguid 1946; Morawska et al. 2009).\nQuesto vuol dire che è molto più semplice bloccare le goccioline appena fuori dalla bocca, quando sono molto più grandi, piuttosto che bloccarle quando raggiungono la faccia e le mucose di una persona non contagiata che viene colpita dalle goccioline in questione. Ma per qualche motivo, questo non è quello su cui gran parte dei ricercatori si è concentrata…"
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-scienze-dei-materiali",
    "href": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-scienze-dei-materiali",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Mascherine e scienze dei materiali",
    "text": "Mascherine e scienze dei materiali\nI dibattiti sull’efficacia delle mascherine spesso partono dal presupposto che lo scopo della mascherina è di proteggere chi la indossa, visto che è quello su cui ci si concentra e si insegna durante la formazione dei medici. In questo le mascherine di stoffa offrono una protezione scadente (pur non essendo del tutto inutili). Per avere una protezione del 100%, chi indossa la mascherina deve avere un respiratore medico (tipo N95) adeguatamente indossato. Ma mascherine di stoffa, indossate da una persona infetta, sono estremamente efficaci nel proteggere le persone circostanti. Questo, in inglese, è detto “source control”, ovvero “controllo alla fonte”. Ed è il controllo alla fonte quello di cui si parla (o di cui si dovrebbe parlare) nel dibattito sulle mascherine per il pubblico.\nSe una persona con COVID-19 tossisce su qualcuno a una ventina di centimetri di distanza, una mascherina di cotone riduce la quantità di virus trasmessa all’altra persona di 36 volte, ed è persino più efficace di una mascherina chirurgica. Curiosamente, i ricercatori che hanno scoperto questa cosa hanno considerato questa riduzione di 36 volte “inefficace”. Noi non siamo d’accordo. Vuol dire trasmettere solamente un 36mo della quantità di virus trasmessa altrimenti, diminuendo la carica virale, con una conseguente probabile riduzione della probabilità di contagio e sintomi più lievi se il contagio avviene."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#la-matematica-della-trasmissione-del-virus",
    "href": "posts/2020-04-19-tutti-in-maschera.html#la-matematica-della-trasmissione-del-virus",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "La matematica della trasmissione del virus",
    "text": "La matematica della trasmissione del virus\nI modelli matematici sviluppati dal nostro team, supportati da altra ricerca (Yan et al. 2019), suggeriscono che se la maggior parte delle persone indossano mascherine in pubblico, il fattore di trasmissione (“R effettivo”), può scendere sotto 1, arrestando la diffusione del virus. La mascherina non deve bloccare ogni singolo virus, ma più ne blocca, più basso è il valore effettivo di R.\n\n\n\nModello dell’impatto dell’uso delle mascherine sul fattore di riproduzione\n\n\nQuanto la diffusione delle mascherine sia efficace dipende da tre fattori illustrati dal diagramma: quanto la maschera blocca il virus (“Efficacy”: l’asse orizzontale), la percentuale della popolazione che indossa le maschere (“Adherence”: l’asse verticale), e il fattore di trasmissione della malattia (R0: le linee nere nel grafico). L’area in blu del diagramma indica un R0 minore di 1, necessario per sconfiggere l’epidemia. Anche se le maschere dovessero bloccare una porzione molto più piccola di particelle virali, la malattia potrebbe comunque essere controllata, ma l’intera popolazione o quasi dovrebbe indossare maschere."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-scienze-politiche",
    "href": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-scienze-politiche",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Mascherine e scienze politiche",
    "text": "Mascherine e scienze politiche\nCome si può far sì che tutti o comunque la maggioranza delle persone indossino maschere? Beh, si può educarle e cercare di convincerle, ma un approccio più efficace è imporre che tutti indossino mascherine, che sia in contesti specifici come sui trasporti pubblici o nei negozi alimentari, o ancor meglio per qualunque motivo si esca da casa. La ricerca sui vaccini (Bradford and Mandich 2015) mostra che nelle aree in cui l’esenzione dai vaccini segue restrizioni più severe, si ha una copertura vaccinale sensibilimente più alta. Lo stesso approccio sta ora venendo utilizzato per ottenere un’adozione più vasta delle mascherine, e risultati preliminari (Leffler et al. 2020) indicano che leggi in tal senso sono efficaci nel migliorare il rispetto della misura e stanno rallentando se non fermando la diffusione di COVID-19."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#esperimenti-con-le-maschere-artificiali-e-naturali",
    "href": "posts/2020-04-19-tutti-in-maschera.html#esperimenti-con-le-maschere-artificiali-e-naturali",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Esperimenti con le maschere: artificiali e naturali",
    "text": "Esperimenti con le maschere: artificiali e naturali\nUn esperimento artificiale si ha quando un ricercatore divide un campione di persone (solitamente a caso, da cui il termine “sperimentazione controllata randomizzata” – randomized controlled trial) in un gruppo che indossa mascherine e un gruppo che non le indossa (il cosiddetto gruppo di controllo). Non ci sono state sperimentazioni controllate randomizzate sull’uso delle mascherine nella popolazione generale nel caso di COVID-19. Sperimentazioni controllate randomizzate nella prevenzione di altre malattie (come l’influenza e la tubercolosi) con l’uso delle mascherine hanno tendenzialmente mostrato un effetto limitato e in molti casi non statisticamente significativo. In molti di questi studi, i soggetti assegnati al gruppo delle mascherine non sempre hanno indossato le mascherine.\nUn esperimento naturale è quando si studia qualcosa che accade al di fuori di un contesto controllato – ad esempio quando una nazione introduce una misura per incrementare l’utilizzo delle mascherine. La Corea del Sud, ad esempio, ha avuto una diffusione interna di COVID-19 che nelle settimane iniziali ha seguito la traiettoria dell’Italia. Verso la fine di febbraio, il governo ha cominciato a fornire una scorta regolare di mascherine a tutti i cittadini. Da quel momento tutto è cambiato. Mentre il numero di morti giornalieri in Italia ha cominciato a crescere a livelli terrificanti, quello della Corea del Sud ha invece cominciato non solo a crescere di meno, ma a diminuire. Questo è il numero di casi attivi in Corea del Sud (in rosso) e in Italia (in blu); osservate cosa succede a inizio marzo, quando la distribuzione delle mascherine ha cominciato a fare effetto (questa analisi è stata fatta da Hyokon Zhiang la visualizzazione da Reshama Shaik):\n\n\n\nParagone dei casi di COVID-19 tra Corea del Sud e Italia\n\n\nGli esperimenti naturali sono scientificamente imperfetti, perché non c’è gruppo di controllo, quindi non possiamo affermare che alcun cambiamento sia dovuto alle mascherine. Alcune nazioni che hanno introdotto una politica sulle mascherine, hanno introdotto più o meno allo stesso tempo altre misure come un rigido distanziamento sociale, la chiusura delle scuole e la cancellazione degli eventi pubblici. Persino in quei casi, però, si possono trovare paragoni interessanti. Ad esempio, l’Austria e la confinante Repubblica Ceca hanno introdotto misure di distanziamento sociale nella stesso giorno, ma la Repubblica Ceca ha introdotto anche l’obbligo di indossare mascherine. In Austria l’infezione ha continuato a peggiorare, mentre in Repubblica Ceca si è appiattita. Finché l’Austria ha introdotto leggi sulle mascherine qualche settimana più tardi e le due nazioni sono tornate su traiettorie simili.\n\n\n\nParagone dei casi di COVID-19 tra Repubblica Ceca e Austria\n\n\nSoprattutto: indipendentemente dal momento, in tutte le nazioni dove l’uso delle mascherine è stato incoraggiato per legge, o in cui le mascherine sono state distribuite alla popolazione, il numero di casi e di morti giornalieri è precipitato."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-scienze-comportamentali",
    "href": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-scienze-comportamentali",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Mascherine e scienze comportamentali",
    "text": "Mascherine e scienze comportamentali\nAlcuni sostengono (Brosseau et al. 2020) che costringere o incoraggiare le persone a indossare mascherine incoraggerebbe comportamenti rischiosi nella popolazione (ad esempio, uscire di più o lavarsi le mani di meno), con un risultato netto negativo, come osservato in alcuni controlli sperimentali con le mascherine. Alcune argomentazioni simili sono state usate contro l’adozione di strategie di prevenzione per HIV (Cassell et al. 2006; Rojas Castro, Delabre, and Molina 2019) o leggi per l’obbligo dei caschi sui motocicli (Ouellet 2011). Tuttavia, la ricerca sul campo in questi ambiti ha evidenziato che anche se alcuni individui rispondono con un comportamento rischioso, a livello di popolazione si osserva un miglioramento della sicurezza e del benessere (Peng et al. 2017; Houston and Richardson 2007)."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#mascherine-ed-economia",
    "href": "posts/2020-04-19-tutti-in-maschera.html#mascherine-ed-economia",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Mascherine ed economia",
    "text": "Mascherine ed economia\nAlcune analisi economiche hanno confrontato il costo di distribuire mascherine con il valore (economico e non) che si potrebbe ottenere – o potenzialmente perdere – se fossero distribuite. Questi studi economici (Abaluck et al. 2020) indicano che ogni maschera indossata da una persona (che ha un costo praticamente nullo) potrebbe generare benefici economici di migliaia di dollari e salvare molte vite."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-antropologia",
    "href": "posts/2020-04-19-tutti-in-maschera.html#mascherine-e-antropologia",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Mascherine e antropologia",
    "text": "Mascherine e antropologia\nIndossare mascherine in pubblico è diventata una cosa normale in molte nazioni asiatiche, sia per motivi individuali (per proteggersi dall’inquinamento) che collettivi (come risultato delle recenti epidemie di MERS e SARS). La mia mascherina ti protegge, la tua mascherina mi protegge. Nella maggioranza di queste nazioni, però, la norma era di indossare mascherine solo quando si presentano dei sintomi; solo nelle ultime settimane, con l’aumentare della consapevolezza sui contagi da parte di asintomatici, l’abitudine di indossare le maschere a prescindere dai sintomi si è diffusa."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#conclusioni",
    "href": "posts/2020-04-19-tutti-in-maschera.html#conclusioni",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Conclusioni",
    "text": "Conclusioni\nAnche se non tutte le evidenze scientifiche supportano la diffusione delle mascherine, la maggior parte puntano nella stessa direzione. Il nostro esame delle evidenze disponibili ci ha portato a una conclusione chiara: tenetevi le vostre goccioline – indossate mascherine.\nNon è difficile farsele da soli con una maglietta, un fazzoletto, un pezzo di carta da cucina o anche semplicemente indossando una sciarpa o una bandana sulla faccia. Idealmente, utilizzate un tessuto stretto che permette di respirare. I ricercatori raccomandano di includere uno strato di carta da cucina o un filtro usa e getta; potete semplicemente aggiungerlo tra due strati di tessuto. Non c’è alcuna evidenza che una mascherina debba essere fatta con mezzi speciali per essere efficace nel controllo alla fonte. Una mascherina di stoffa può essere lavata e riutilizzata, proprio come una maglietta.\nA quanto pare, se state incubando COVID-19, le persone a cui tenete vi saranno grate per aver indossato una mascherina."
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#epilogo-jeremy-mostra-come-funziona-il-controllo-alla-fonte",
    "href": "posts/2020-04-19-tutti-in-maschera.html#epilogo-jeremy-mostra-come-funziona-il-controllo-alla-fonte",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Epilogo: Jeremy mostra come funziona il controllo alla fonte",
    "text": "Epilogo: Jeremy mostra come funziona il controllo alla fonte\nEcco un piccolo esperimento di Jeremy sul controllo alla fonte!"
  },
  {
    "objectID": "posts/2020-04-19-tutti-in-maschera.html#riferimenti",
    "href": "posts/2020-04-19-tutti-in-maschera.html#riferimenti",
    "title": "Tutti in maschera? La scienza dice sì",
    "section": "Riferimenti",
    "text": "Riferimenti\n\nAbaluck, Jason, Judith A. Chevalier, Nicholas A. Christakis, Howard Paul Forman, Edward H. Kaplan, Albert Ko, and Sten H. Vermund. 2020. “The Case for Universal Cloth Mask Adoption and Policies to Increase Supply of Medical Masks for Health Workers.” SSRN Scholarly Paper ID 3567438. Rochester, NY: Social Science Research Network. https://papers.ssrn.com/abstract=3567438.\nBai, Yan, Lingsheng Yao, Tao Wei, Fei Tian, Dong-Yan Jin, Lijuan Chen, and Meiyun Wang. 2020. “Presumed Asymptomatic Carrier Transmission of Covid-19.” Jama.\nBradford, W David, and Anne Mandich. 2015. “Some State Vaccination Laws Contribute to Greater Exemption Rates and Disease Outbreaks in the United States.” Health Affairs 34 (8): 1383–90.\nBrosseau, Lisa M., ScD, Margaret Sietsema, PhD Apr 01, and 2020. 2020. “COMMENTARY: Masks-for-All for COVID-19 Not Based on Sound Data.” CIDRAP. https://www.cidrap.umn.edu/news-perspective/2020/04/commentary-masks-all-covid-19-not-based-sound-data.\nCassell, Michael M, Daniel T Halperin, James D Shelton, and David Stanton. 2006. “Risk Compensation: The Achilles’ Heel of Innovations in Hiv Prevention?” Bmj 332 (7541): 605–7.\nDoremalen, Neeltje van, Trenton Bushmaker, Dylan H. Morris, Myndi G. Holbrook, Amandine Gamble, Brandi N. Williamson, Azaibi Tamin, et al. 2020. “Aerosol and Surface Stability of SARS-CoV-2 as Compared with SARS-CoV-1.” New England Journal of Medicine 0 (0): null. https://doi.org/10.1056/NEJMc2004973.\nDuguid, JP. 1946. “The Size and the Duration of Air-Carriage of Respiratory Droplets and Droplet-Nuclei.” Epidemiology & Infection 44 (6): 471–79.\nHouston, David J, and Lilliard E Richardson. 2007. “Risk Compensation or Risk Reduction? Seatbelts, State Laws, and Traffic Fatalities.” Social Science Quarterly 88 (4): 913–36.\nLeffler, Christopher, Edsel Ing, Craig A. McKeown, Dennis Pratt, and Andrzej Grzybowski. 2020. “Country-Wide Mortality from the Novel Coronavirus (COVID-19) Pandemic and Notes Regarding Mask Usage by the Public.”\nMorawska, LJGR, GR Johnson, ZD Ristovski, Megan Hargreaves, K Mengersen, Steve Corbett, Christopher Yu Hang Chao, Yuguo Li, and David Katoshevski. 2009. “Size Distribution and Sites of Origin of Droplets Expelled from the Human Respiratory Tract During Expiratory Activities.” Journal of Aerosol Science 40 (3): 256–69.\nOuellet, James V. 2011. “Helmet Use and Risk Compensation in Motorcycle Accidents.” Traffic Injury Prevention 12 (1): 71–81.\nPeng, Yinan, Namita Vaidya, Ramona Finnie, Jeffrey Reynolds, Cristian Dumitru, Gibril Njie, Randy Elder, et al. 2017. “Universal Motorcycle Helmet Laws to Reduce Injuries: A Community Guide Systematic Review.” American Journal of Preventive Medicine 52 (6): 820–32.\nRojas Castro, Daniela, Rosemary M Delabre, and Jean-Michel Molina. 2019. “Give Prep a Chance: Moving on from the ‘Risk Compensation’ Concept.” Journal of the International AIDS Society 22: e25351.\nTo, Kelvin Kai-Wang, Owen Tak-Yin Tsang, Wai-Shing Leung, Anthony Raymond Tam, Tak-Chiu Wu, David Christopher Lung, Cyril Chik-Yan Yip, et al. 2020. “Temporal profiles of viral load in posterior oropharyngeal saliva samples and serum antibody responses during infection by SARS-CoV-2: an observational cohort study.” Lancet Infect. Dis. 0 (0). https://doi.org/10.1016/S1473-3099(20)30196-1.\nWei, Wycliffe E. 2020. “Presymptomatic Transmission of SARS-CoV-2 â€” Singapore, January 23â€“March 16, 2020.” MMWR. Morbidity and Mortality Weekly Report 69. https://doi.org/10.15585/mmwr.mm6914e1.\nWells, WF. 1934. “On Air-Borne Infection: Study Ii. Droplets and Droplet Nuclei.” American Journal of Epidemiology 20 (3): 611–18.\nYan, Jing, Suvajyoti Guha, Prasanna Hariharan, and Matthew Myers. 2019. “Modeling the Effectiveness of Respiratory Protective Devices in Reducing Influenza Outbreak.” Risk Analysis 39 (3): 647–61. https://doi.org/10.1111/risa.13181.\nZhang, Juanjuan, Maria Litvinova, Wei Wang, Yan Wang, Xiaowei Deng, Xinghui Chen, Mei Li, et al. 2020. “Evolving Epidemiology and Transmission Dynamics of Coronavirus Disease 2019 Outside Hubei Province, China: A Descriptive and Modelling Study.” The Lancet Infectious Diseases 0 (0). https://doi.org/10.1016/S1473-3099(20)30230-9.\nZou, Lirong, Feng Ruan, Mingxing Huang, Lijun Liang, Huitao Huang, Zhongsi Hong, Jianxiang Yu, et al. 2020. “SARS-CoV-2 Viral Load in Upper Respiratory Specimens of Infected Patients.” New England Journal of Medicine 382 (12): 1177–9. https://doi.org/10.1056/NEJMc2001737."
  },
  {
    "objectID": "posts/2020-06-03-data-vis-fundamentals.html",
    "href": "posts/2020-06-03-data-vis-fundamentals.html",
    "title": "Fundamentals of Data Visualisation",
    "section": "",
    "text": "Visualising data is all too often an overlooked skill of data people, especially by the data scientist/machine learning engineer fraction of the population.\nThis is somewhat similar to what happens with the front end/back end divide in software engineering. Just as I don’t believe in true full stack engineers, because the amount of tools and speed at which they evolve is simply too much for a single person to master at the same time, I don’t believe that it is reasonable to expect a single data professional to be an expert in all the aspects of the data process.\nAt the same time, I do believe that software engineers who can cover the fundamentals of full stack development while maintaing a deeper expertise in some aspect or another exist, and I call them good software engineers. In the same fashion, I think that good data professionals should have a good working understanding of all the steps of the data process no matter whether they are generalists or hyper specialised.\nThis is especially true for data visualisation as it is fundamental in at least two very distinct stages at the opposite ends of the data process, so I believe it is very relevant to all data professionals."
  },
  {
    "objectID": "posts/2020-06-03-data-vis-fundamentals.html#rule-n.1-start-with-why-and-who",
    "href": "posts/2020-06-03-data-vis-fundamentals.html#rule-n.1-start-with-why-and-who",
    "title": "Fundamentals of Data Visualisation",
    "section": "Rule n.1: Start with why, and who",
    "text": "Rule n.1: Start with why, and who\nThis is really the first rule of any kind of presentation, not only data visualisation.\nData visualisation is not (or should not be) a pretty picture for its own sake: it is made to communicate something to someone. It is fundamental when creating visualisations to start and always keep in mind both the message and the intended audiance.\nA good exercise is to explicitly articulate why the visualisation is being made before actually building it. It is very unlikely we will be able to convey a message we are not able to articulate to ourselves.\nEven if the message is extremely clear, there is no single way of building a visualisation. Context and audience matter. A lot.\n\nA cautionary tale\nOn the morning of the 27 of January 1986, NASA managers of the Marshall Space Center were having a teleconference to address concerns about a Shuttle launch that had been rescheduled from that morning to the next day because of weather issues.\nAmong other things, they were addressing concerns that the engineering team at Morton Thiokol Inc., the company that had produced the solid rocket boosters of the Shuttle, had about the effects that the cold temperatures forecasted for the next day might have on the O-Rings of the boosters.\nThe engineers at MTI presented this chart to illustrate their concerns on the topic:\n\nAt the time NASA hadn’t been recommended anything explicitely (this would happen later in the afternoon), as per later testimonies, they were just “looking at the engineering data”, so they decided that those concerns were negligible and went ahead with the launch.\nThe next day the Challenger launched as scheduled.\n\nAlthough it has been speculated, it is probably not the case that the low temperature has been the main cause of the disaster, so it’s an exaggeration to say that bad data visualisation has destroyed the Challenger, but it is quite clear that the chart above does not bring the message across.\nThere are a number of capital mistakes, but to stay on topic of rule n.1, if you want to show the risk of damage to the O-Rings deriving from low temperatures, then:\n\nDon’t make the temperature hard to read: that’s the main reason you are making this visualisation\nDon’t hide the legend that clarifies the damage to the O-rings in another slide: you are hiding your message\nDon’t sort by time: it’s irrelevant here, and it is shifting the attention from the message you are trying to convey\n\nAnd on the topic of “know your audience”: that chart has been prepared to be shown to NASA management deciding on the safety of a launch, not on a magazine for the general public, you really don’t need all those rockets boosters pictures.\nAs Tufte (famous statistician and data vis expert) has possibly overemphasized, the message “low temperatures can damage the o-rings more than we feel confortable with” might have been better served by something like this\n\n(Image coming from this Stanford magazine article)\nWhatever the correct way of displaying the message is, in the original chart you can spot a huge red flag in the lower left corner, that reads:\n\nInformation on this page was prepared to support an oral presentation and cannot be considered complete without the oral discussion\n\nWhenever you spot a warning of this kind, it is often a sign that the authors don’t feel confident about their presentation or data visualisation or don’t want to assume responsability for that. Try not to be that author.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure your data visualisations can stand on their legs and can convey the intended message to the intended audience."
  },
  {
    "objectID": "posts/2020-06-03-data-vis-fundamentals.html#rule-n.2-dont-lie",
    "href": "posts/2020-06-03-data-vis-fundamentals.html#rule-n.2-dont-lie",
    "title": "Fundamentals of Data Visualisation",
    "section": "Rule n.2: Don’t lie",
    "text": "Rule n.2: Don’t lie\nSince any single element of a data visualisation explictly or implicitly carries meaning, there are also countless possibilities of lying with it.\nWhen I say “lying”, I mean it in a broad “creating a wrong interpretation of the data in the audience” kind of way, as it does not need to be intentional.\nSince every data visualisation should have a clear message and intended audience, there are a number of ways of distorting that message.\nRather than talking in abstract about how not to lie, I find more useful to look at examples of lying charts. Whether the author intended to do that or not.\n\nA menagerie of lying charts\n\nLying with data and scales\nThe first and most obvious way of lying with a data visualisation is by manipulating or omitting the data itself. Take a look at the following graph, that shows how the pollution has dropped since a certain party has taken power (the country and party are not important in this context).\n\nOf course a distracted voter would not notice that three years (when pollution actually went up) are missing from the chart.\nAlso notice that the same chart pulls the old trick of “let’s remove the 0 from the y axis so that a 2% change looks like a reduction of more than 50%”. Two lies for one.\nAs I said, lying with charts does not need to be intentional: speaking of y axes and scales, you can also err in the opposite direction, by being too honest and mixing quantities that should not be on the same scale.\n\nThe result is a chart that is technically correct, but does not convey any useful information (at least for what concerns the temperature).\n\n\nLying with mappings and aesthetics\nNext on our list are the so called “mappings”, i.e. the way we project dimensions of our data (the features, if you will) onto the characteristic of the graphical objects of the chart (the “aesthetics”).\nAs usual, this can be clumsy/unintentional, like mapping an ordinal variable like binned years onto a non gradient color palette of a stacked bar chart, resulting in a chart that is definitely not easy to read (at least in the temporal dimension):\n\nOr it can be absolutely blatant, like using a bar chart and implying a mapping that is not there, pretending that the mapped feature is represented by the height of the bars (which is clearly not the case)\n\nOr it can be more sneaky, like mapping an ordinal variable onto an ordinal aesthetic (the position on the x axis), but sorting it according to something else, effectively treating an ordinal variable like a categorical, non ordered, one. Notice how the days on the x axis are not in chronological order, to make a decreasing trend appear out of thin air.\n\nOne of the most common way of lying with aestetics, which is mostly uninententional, is to use the wrong colours. Picking the right colours for your data visualisation is no easy task, but one rule of thumb is: never use the rainbow colour palette.\nThere are a lot of reasons for this, but the summary is that it has unintuitive hues shift (and we subconsciously associate meanings to colours) and that it can have similar hues for values that are actually far away on the scale. As an example, look how similar the pink and red hues (which are at the opposite ends of the scale) are in the following chart.\n\n\n\nLying with geoms\nNext element that can be used to make a lying data visualisation is the choice of geometric object (or “geom”, in the language of the grammar of graphics). By far the most common offender is the use of a pie chart (or even worse, a donut chart) for categorical variables with a lot of categories.\n\nAlthough there is some controversy on this point, the reason why pie chart should be avoided is that they use angles to represent quantities, and the human eye is very bad at estimating angles. This problem is exacerbated with donut charts, where the missing central circle makes understanding the quantities even harder. In general, a pie chart should only be used for no more than 2-3 categories, when the quantities are very different and the actual numbers are explicitly presented or only a rough comparison is needed (and as said before: your visualisation should be able to stand on its legs, having to write down the actual data is a red flag). Dount charts and gauges should only be considered eye candy for raw values.\nOn the other hand, if you really want to make it nigh impossible to evaluate quantities, using a 3D pie chart is a great ways to distort the sizes of the slices to make comparisons look whatever you want them to look.\n\nIn general the addition of 3D to a visualisation is always a bad idea, as it adds nothing and often actively distorts the message.\nLet it be noted that I blame MS Office for the all too frequent presence of 3D charts.\nWrong geoms are not restricted to 3D and pie charts though: in the following graph, for example, the choice of a line plot implies the presence of a trend among independent categories (on the x axis we have a categorical variable, not an ordinal one). Line plots are very useful for ordinal vairables and especially time variables, but not in this case.\n\nNotice that in the chart there is no real mistake, but the line suggests a relationship between cities that are close on the x axis, while they are just sorted by the percentage of AC ownership in households.\nAnother common class of lying geoms is pictograms in infographics. The problem here is that more often than not we see the underlying variable mapped to the radius of the picture, while looking at pictures we instinctively compare the areas, which go with the square of the radius. Notice, for example, how in the following infographics, in the “Skipping breakfast” section a bowl which is four times larger than the one next to it is used to represent a quantity that is roughly twice the other.\n\nA better solution is actually used in the “office romance” section (second to last) of the same infographic, where the dimension is mapped onto the number of copies of the same picture. Less visually appealing for sure, but more truthful. An alternative solution would be mapping the variable to the actual area of the picture, but that makes the comparison harder to make (because we are worse at comparing areas), unless the quantity itself is an area.\nGood infographics are tricky to make.\n\n\nLying with other elements\nIf you really do not want to lie with the chart itself, you still have the possibility of using the additional elements, like labels, scales, legends and so on.\nThis is often done by omission.\nI am pretty sure that “label your axis” is a mantra that we have all heard at school, but what better way to produce a visualisation that has really little explanatory power, but gives a sense of “backed up by data” to what is effectively a marketing ad?\n\nAnother possibility is to put the legend far away from the actual chart, so that the eye constantly has to go back and forth before essentially giving up. For maximum effect, remove any number, sort the legend in an imperscrutable way, adopt a colour palette that has several similar hues for unrelated categories and, of course, use a donut chart for many similar quantities.\n\nOr if you really, really want to go overboard, add a messed up mapping, and you have successfully achieved The Sun level of data visualisation\n\n\n\n\n\n\n\nImportant: Unless you really know what you are doing, avoid pie charts and donut charts and avoid the rainbow colour palette. Pay attention to all the elements of your data visualisation."
  },
  {
    "objectID": "posts/2020-06-03-data-vis-fundamentals.html#rule-n.3-reduce-the-noise-amplify-the-signal",
    "href": "posts/2020-06-03-data-vis-fundamentals.html#rule-n.3-reduce-the-noise-amplify-the-signal",
    "title": "Fundamentals of Data Visualisation",
    "section": "Rule n.3: Reduce the noise, amplify the signal",
    "text": "Rule n.3: Reduce the noise, amplify the signal\nEdward Tufte, whom I have mentioned while talking about the Challenger disaster, coined the term “Chartjunk” to refer to all the unnecessary elements of the chart that distract from the data itself. “Maximising the the data-ink ratio” is one of Tufte’s rule, by which he means that we should consider reduce as much as possible all the “ink” (this was an era when data visualisation tended not to sit on a screen) that is not representing the data. This is a very good rule of thumb, and in the process of developing a good aestethic for effective data visualisation I strongly advise to practice the art of minimalist charts. The problem is that this can easily go too far if followed to the letter. The idea behind my 3rd rule is to remove whatever distracts and add whatever conveys the message. It is true that we should let the data speak for itself, but data has a very faint voice, and we should make sure that its whisper is heard loud and clear.\nThe following is often found as an example of bad visualisation, due to the very low data-ink ratio and the amount of chartjunk.\n\nI actually disagree: this is a visualisation made for a Time magazine issue dedicated to the price of diamonds. Its message is extremely clear (the price of diamonds has fallen), and its intended audience are the readers of Time magazine, not diamond traders; in this case even the actual numbers are probably not that important, if not to convey some sense of scale.\nThe visualisation clearly conveys the intended message to the intended audience and does so capturing the attention in a way more effective way than a boring and clean chart would have made. As such, I consider it an excellent storytelling data visualisation.\n\n\n\n\n\n\nImportant\n\n\n\nThe most important thing is that your message is clear. Remove what distracts from it and add elements that emphasize it. But Rule n.1 and 2 take precedence."
  },
  {
    "objectID": "posts/2020-06-03-data-vis-fundamentals.html#conclusions",
    "href": "posts/2020-06-03-data-vis-fundamentals.html#conclusions",
    "title": "Fundamentals of Data Visualisation",
    "section": "Conclusions",
    "text": "Conclusions\nData visualisation is a vast field (in which I am not an expert) and a deep rabbit hole to look into, but I hope to have been able to condense into my three rules some simple fundamental principles that can help you making good data visualisation independently of your role, experience and tools of choice. I find that these set of rules are a useful lens that help me understand the thinking behind a lot of what I read on the topic, which at the same time, makes it easier to learn. Hopefully it will work for you too."
  },
  {
    "objectID": "posts/2020-06-03-data-vis-fundamentals.html#additional-material",
    "href": "posts/2020-06-03-data-vis-fundamentals.html#additional-material",
    "title": "Fundamentals of Data Visualisation",
    "section": "Additional material",
    "text": "Additional material\nIf you want to delve deeper into the topic, I suggest to have a look at the following material, in no particular order. No affiliate links.\n\nSame Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing the paper about the “Datasaurus dozen”\nEdward Tufte’s website. Tufte’s a recognised name, although a bit extreme in his views sometimes.\nOn the subject of finding the “why” and “who” of data visualisations the booklet Making Data Visual presents the interesting concept of “data interview”. I think it is a nice little read.\nviz.wtf your daily dose of graph “mistakes”, most of the examples I used are coming from this website\nA very good and detailed Medium article on visualising data in high dimensions, with a lot of good advice\nVisual storytelling with D3, although specifically aimed at D3.js, the author is one of the data journalists behind the excellent visualisations at 538 and the book contains a lot of general good advice\nA discussion on when “eliminating chartjunk” can go too far (this is the reason behind the “amplify the signal” part of rule n.3 we have talked about). And a sensible improvement on Tufte’s definition of chartjunk\nThe original paper on the layered grammar of graphics, which has given us ggplot. Extremely useful to understand what data plots are from a technical points of view and to get the hang of the best plotting libraries. From the same author of the Medium post on the visualisations of high dimensional data, we have one specifically on the same topic, but specifically aimed at explaining the grammar of graphics approach. Very useful even if R and ggplot are not your thing\nThe podcast Data Stories and in particular the episode dedicated to colours. Although it is not superexciting, the podcasts contains a lots of gems\nThe Data Science Design Manual (free to download from Springer’s website for the time being). And in particular the chapter on exploratory data analysis and data visualisation. The whole book is a bit dated in its views in my opinion, but it is a good organised review of the data process\nDarrell Huff’s How to lie with statistics a classic and a must read for every data professional\nMore specifically dedicated to data plots, How to lie with charts"
  },
  {
    "objectID": "posts/2020-05-06-palle-cubiche.html",
    "href": "posts/2020-05-06-palle-cubiche.html",
    "title": "Palle cubiche (minipost)",
    "section": "",
    "text": "In maniera più o meno legittima, in tempi di pandemia chiunque abbia avuto un minimo di infarinatura statistica (me compreso) si è dilettato a fare modelli di evoluzione del contagio. Come data scientist, e il mio passato da matematico aiuta, ho imparato che una delle cose più importanti quando si produce un modello è cercare in tutti i modi di trovarne i limiti e comunicare le possibili fonti di errore. Tutti i modelli sono sbagliati, e non preoccuparsi delle conseguenze di questi errori, può avere e spesso ha effetti catastrofici (ci sono decine di esempi, soprattutto con gli algoritmi più sofisticati, ma questo è un discorso per una lunga serie di post).\nParticolarmente grave, quindi, quando un organo ufficiale si vanta a sproposito di un proprio modello, come in questo caso\n\n\n\n\n\n\nL’account del tweet (che per i non anglofoni essenzialmente dice che grazie alle nuove informazioni ottenute su COVID hanno costruito un “modello cubico” che funziona molto bene e che, come implica la figura, può essere usato per predirre l’andamento dell’epidemia negli USA) appartiene al “Council of Economic Advisers” della Casa Bianca, un organo ufficiale del governo degli USA.\nA molti è saltato subito agli occhi che il “modello cubico” sembra non essere altro che un fitting polinomiale di terzo grado fatto in pochi secondi con Excel (qui, ad esempio il commento di Nate Silver, tanto per appellarsi all’autorità)\n\n\n\n\n\n\nMa il problema non è nemmeno tanto l’utilizzo di un modello semplice. Ma che il modello è fatto ad arte per mostrare che l’epidemia è quasi finita e quindi è il momento di riaprire tutto.\nChe problemi ci sono con il nostro “modello cubico”?\n\nPrima di tutto utilizza come unico fattore predittivo del numero di morti giornaliero… la data. La cosa va anche bene quando si vuole mostrare cosa succederà nel breve termine se niente cambia nell’andamento attuale, ma ha un valore predittivo molto debole e non può essere utilizzato per predire un cambio di andamento (questo, ad esempio, è un errore che ho visto commettere a fin troppi matematici a inizio epidemia, nel tentare di capire quando sarebbe arrivato “il picco” o, per i più raffinati, “il flesso”; purtroppo sapere cos’è un’esponenziale o un modello logistico non attrezza a fare previsioni in pratica).\nSecondo questo modello, tra una settimana o poco più si arriva a zero contagi negli USA. Questo è il messaggio che si vuole far passare, ma è quanto meno molto poco probabile\nSe non fosse stato tagliato ad arte, lo stesso modello ci dice che verso inizio dicembre l’intera popolazione mondiale è morta di COVID e non ce ne siamo accorti\nSempre estendendo il nostro “modello cubico”, questa volta nel futuro, realizziamo che intorno al 20 maggio i morti iniziano a tornare in vita in numeri sempre più abbondanti\n\nPer capire cosa intendo negli ultimi due punti, basta osservare che una curva del tipo utilizzato nel nostro modello cubico ha, più o meno, una forma come in figura\n\n\n\nUn modello cubico in azione…\n\n\nCertamente tutto questo sostiene quanto detto da Trump a suo tempo che l’epidemia “scomparirà come fosse un miracolo”, ma aspettarsi che i morti tornino in vita è forse un po’ esagerato persino per lui. Ed è evidente che un modello che è sicuramente completamente sbagliato in 2 settimane, non ha alcun valore predittivo a una settimana.\nMa il problema grave è che stiamo parlando di un organo di stato ufficiale che spara idiozie spacciandole per certezze.\nPalle cubiche, appunto.\nElon Musk con un solo tweet ha prodotto miliardi di dollari di danni a Tesla, ma qui si tratta di persone che moriranno a causa di questo tweet.\nQuesto non è e non può essere accettabile.\n\n\n\nPS: non posso esimermi dal ricordare che anche in Italia alcuni economisti hanno a suo tempo previsto zero contagi per questa settimana (e a quanto pare in Piemonte non ci sono più contagi già da 2 o 3 settimane, si vede che ci siamo sbagliati tutti). A onor del vero, all’inizio gli autori hanno sottolineato come la loro fosse una semplice analisi da non usare in senso predittivo. Ma con l’attenzione mediatica (e il Corriere è responsabile in questo caso) l’iniziale cautela è stata presto abbandonata."
  },
  {
    "objectID": "posts/2020-03-07-private-fastpages-on-kubernetes.html",
    "href": "posts/2020-03-07-private-fastpages-on-kubernetes.html",
    "title": "Private FastPages on Kubernetes",
    "section": "",
    "text": "This post is the very reason I decided myself to go back to blogging. I managed to do something that I considered relatively trivial, but let others know about it in the Fast.ai forums it turned out not to be that obvious after all. And writing about it, I realised that not even a year ago, I wouldn’t have had the faintest idea of what I am talking about here."
  },
  {
    "objectID": "posts/2020-03-07-private-fastpages-on-kubernetes.html#context",
    "href": "posts/2020-03-07-private-fastpages-on-kubernetes.html#context",
    "title": "Private FastPages on Kubernetes",
    "section": "Context",
    "text": "Context\n\n\n\n\n\n\nNote\n\n\n\nIf you are not part of a mid-large company IT department, the following paragraph might sound like a bunch of corporate lingo that makes no sense. It is not completely true, but if you have no idea what I am talking about, just skip it.\n\n\nAs a mathematician turned knowledge engineer turned product manager turned data scientist with a pench for learning new stuff, one of the many hats I tend to wear quite often is that of knowledge sharer. Since in my current role I am helping setting up a federated team of data analysts, one of the problems we need to solve is breaking the information siloes among data people. This way we can avoid duplicate work and we can piggyback on each others’ research in order to extract more advanced insights.\nSince I am a bit of a Fast.ai fanboy and I am using Jupyter a lot in my data work, when fast_template/FastPages was presented, I started thinking about how to deploy it for my use case. The main blocker was that GitHub pages are always public, even on private repos, which would have been a showstopper, as we don’t want to police a self serving tool to check that no important information is being shared publicly."
  },
  {
    "objectID": "posts/2020-03-07-private-fastpages-on-kubernetes.html#summary-andor-tldr",
    "href": "posts/2020-03-07-private-fastpages-on-kubernetes.html#summary-andor-tldr",
    "title": "Private FastPages on Kubernetes",
    "section": "Summary (and/or TL;DR)",
    "text": "Summary (and/or TL;DR)\nIn order to deploy FastPages privately on a Kubernetes cluster you need to: 1. Change the branch to which the website built by Jekyll is pushed 2. Deploy a static webpage server (I used Nginx) with a Git-sync sidecar to keep the served site up to date 3. Makesure the sidecar can pull the fastpages repo with a read only deploy key 4. Expose the server internally with appropriate network policies and ingress configurations\nWhile steps 1-3 are fairly straightforward, the last step depends heavily on your cluster configuration and policies. I will give a very high level description of what I did, but you will have to do your own research to make it work in your case.\n\nRequirements\nThis guide is not too beginner friendly and it is not meant to be: since the risk of getting it wrong is exposing private information, you need to have some working knowledge of what you are doing or at least some way of making sure that you are not doing huge mistakes (like a SRE/DevOps person to review what you are doing). Other than that you need - Access and admin privileges to private GitHub repos - The ability of running GitHub actions on the private repos - A Kubernetes cluster set up with appropriate network policies and DNS - A namespace that can access the private GitHub repo. This is usually the case, but if your cluster is super locked down, it might not be possible\n\nImportant: to make the deployment, you need to know your way around Kubernetes. You just need to know how to use it and deploy/manage resources into it, you don’t need cluster admin knowledge of any kind"
  },
  {
    "objectID": "posts/2020-03-07-private-fastpages-on-kubernetes.html#setting-up-fastpages",
    "href": "posts/2020-03-07-private-fastpages-on-kubernetes.html#setting-up-fastpages",
    "title": "Private FastPages on Kubernetes",
    "section": "Setting up FastPages",
    "text": "Setting up FastPages\nFirst of all you have to setup your FastPages repo. Just follow the latest instructions (keep in mind that the tool is under active development, so those might change quite often); this will trigger a GitHub action that will open a PR. Before following the instructions in the PR, there is a few things to do to avoid fastpages publishing private stuff by mistake. 1. Set a branch protection rule to make sure that at least two approving reviews are required to push to the gh-pages. This is because by default, as soon as something is pushed to the gh-pages branch, it gets published on GitHub pages. As far as I know, there is no way to prevent this behaviour. 2. Checkout into the branch that has been opened by the Setup action (the one that the open PR is attempting to merge into master) and modify the .github/workflows/ci.yaml from this\n    - name: Deploy\n      if: github.event_name == 'push'\n      uses: peaceiris/actions-gh-pages@v3\n      with:\n        deploy_key: ${{ secrets.SSH_DEPLOY_KEY }}\n        publish_dir: ./_site\nto something like this (you can pick whatever branch name you want)\n    - name: Deploy\n      if: github.event_name == 'push'\n      uses: peaceiris/actions-gh-pages@v3\n      with:\n        deploy_key: ${{ secrets.SSH_DEPLOY_KEY }}\n        publish_branch: private-website-branch\n        publish_dir: ./_site\nAfter this you are can continue setting up the repo according to the instructions in the PR.\nThis is all that is needed on the FastPages side of things.\n\nGotchas and other optional steps\nIf you want the website to function in any useful way, you will have to set up an internal domain. How to do so depends heavily on how the DNS and network policies are setup in your Kubernetes cluster. If your domain is going to be, for example shiny.private.website, you want to make sure to that - Your CNAME file (so that the categories work properly, for example) contains shiny.private.website - The _config.yml file contains\nurl: \"https://shiny.private.website\" # the base hostname & protocol for your site, e.g. http://example.com\nbaseurl: \"\"\nBefore you merge the setup PR (or right after that), it is also a good idea to create an upstream branch and to set its remote to the original FastPages repo, so that you can keep your deployment in sync with the development of FastPages.\nDon’t do it later as I did. It’s a pain to solve the merge conflicts."
  },
  {
    "objectID": "posts/2020-03-07-private-fastpages-on-kubernetes.html#deploying-the-server",
    "href": "posts/2020-03-07-private-fastpages-on-kubernetes.html#deploying-the-server",
    "title": "Private FastPages on Kubernetes",
    "section": "Deploying the server",
    "text": "Deploying the server\nSince Jekyll builds a complete static website and the github action pushes it to the branch we have set up in the step above, we only need something capable of serving it. I have used a basic Nginx alpine image, but there are probably a thousand different options. In order to avoid having to redeploy the server manually everytime, furthermore, we want to add a git-sync sidecar that pulls the website branch into the served folder of the Nginx container and keeps it up to date. There are a few possible variations but this is how more or less how the manifest would look like\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: your-namespace\nspec:\n  selector:\n      matchLabels:\n          app: fastpages\n  replicas: 1 # You can set this to something higher if needed\n  template:\n    metadata:\n        labels:\n            app: fastpages\n    spec:\n        restartPolicy: Always\n        securityContext:\n            fsGroup: 65533 # to make SSH key readable \n        containers:\n        - name: fastpages\n          image: nginx:alpine\n          imagePullPolicy: Always\n          volumeMounts:\n          - name: site\n            mountPath: /usr/share/nginx/html\n          - mountPath: /etc/nginx/conf.d\n            name: fastpages-conf\n          ports:\n          - containerPort: 80\n            protocol: TCP\n          resources:\n            limits:\n              memory: 20Mi\n        - name: git-sync\n          image: k8s.gcr.io/git-sync\n          imagePullPolicy: IfNotPresent\n          env:\n            - name: GIT_SYNC_REPO\n              value: \"git@github.com:your-githubname/yourprivaterepo.git\"\n            - name: GIT_SYNC_DEST\n              value: \"www\"\n            - name: GIT_SYNC_ROOT\n              value: \"/site\"\n            - name: GIT_SYNC_SSH\n              value: \"true\"\n            - name: GIT_SYNC_MAX_SYNC_FAILURES\n              value: \"5\"\n          resources:\n            requests:\n              cpu: 0m\n              memory: 0Mi\n            limits:\n              memory: 200Mi\n          securityContext:\n            runAsUser: 65533 # git-sync user\n          volumeMounts:\n          - name: git-secret\n            mountPath: /etc/git-secret\n          - name: site\n            mountPath: /site\n        volumes:\n        - name: site\n          emptyDir: {}\n        - configMap:\n            defaultMode: 420\n            name: fastpages-conf\n          name: fastpages-conf\n        - name: git-secret\n          secret:\n            secretName: fastpages-git-ssh\n            defaultMode: 0400\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: fastpages\nspec:\n  selector:\n    app: fastpages\n  ports:\n  - name: http\n    protocol: TCP\n    port: 80\n    targetPort: 80\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n    name: fastpages-conf\n    namespace: your-namespace\ndata:\n    default.conf: |-\n        server {\n            listen       80;\n            server_name _;\n            root /usr/share/nginx/html/www/;\n            access_log /dev/stdout;\n        }\n---\nBefore deploying the above, generate a new SSH key pair and create a secret with the private key in your namespace called fastpages-git-ssh. After that use the public key of the pair to create a new read only deploy key on your FastPages repo.\nOnce all this is done, you can deploy the above and you webserver container should start happily. Sadly, you will not be able to access it yet if your namespace has properly set policies.\n\nImportant: Please be careful of how you manage your secrets, don’t put them on GitHub unencrypted and don’t do anything weird."
  },
  {
    "objectID": "posts/2020-03-07-private-fastpages-on-kubernetes.html#making-the-server-accessible",
    "href": "posts/2020-03-07-private-fastpages-on-kubernetes.html#making-the-server-accessible",
    "title": "Private FastPages on Kubernetes",
    "section": "Making the server accessible",
    "text": "Making the server accessible\nIn order to be expose the served webpages there are probably a couple more resources to be deployed. Both of these are dependent on how your Kubernetes cluster has been set up, so there is not much I can do to help you. In order to make everything work you need 1. An Ingress to expose the HTTP route to the DNS and within the cluster 2. A Netork Policy to make sure that the deployed resources are allowed to communicate among them, if this is not already possible by default in your namespace\nOnce again, if you don’t knwo how to do this, you will have to consult your SRE/DevOps/SystemAdmin team or whoever is maintaining the cluster. Please don’t follow the advice of a random Data Scientist to set up network policies for potentially sensitive resources."
  },
  {
    "objectID": "posts/2020-03-07-private-fastpages-on-kubernetes.html#parting-thoughts",
    "href": "posts/2020-03-07-private-fastpages-on-kubernetes.html#parting-thoughts",
    "title": "Private FastPages on Kubernetes",
    "section": "Parting thoughts",
    "text": "Parting thoughts\nIf you are reading this, you should at this point have a deployment, or know how to get a fastpages powered private website on your Kubernetes cluster.\nI admit that the recipe is quite verbose,but depending on your experience with Kubernetes, these steps might be more or less familiar. If that is not the case, I hope you managed to at least get an idea of what is going on."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "datacasual",
    "section": "",
    "text": "Fundamentals of Data Visualisation\n\n\n\n\n\n\ndata-science\n\n\n\nFirst principles for visual data storytelling. According to me\n\n\n\n\n\nJun 3, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nPalle cubiche (minipost)\n\n\n\n\n\n\nitalian\n\n\ncovid19\n\n\n\nCon COVID siamo tutti data scientist, ma gli organi ufficiali dovrebbero fare meglio\n\n\n\n\n\nMay 6, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nTutti in maschera? La scienza dice sì\n\n\n\n\n\n\nitalian\n\n\ncovid19\n\n\n\nCome e perché in tempo di pandemia tutti dovrebbero indossare una maschera\n\n\n\n\n\nApr 19, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nPrivate FastPages on Kubernetes\n\n\n\n\n\n\nfastpages\n\n\nkubernetes\n\n\n\nHow I deployed FastPages as a tool for our data tribe to share information and insights on the private Kubernetes cluster at my workplace\n\n\n\n\n\nMar 7, 2020\n\n\n\n\n\n\nNo matching items"
  }
]